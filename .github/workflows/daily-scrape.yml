name: Daily UFC Scrape

on:
  schedule:
    # Run at midnight UTC daily (equivalent to the old Celery beat schedule)
    - cron: '0 0 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libnss3 libgdk-pixbuf2.0-0 libglib2.0-0 libx11-xcb1 libxcomposite1 libxrandr2 libasound2t64 libatk-bridge2.0-0 libatk1.0-0 libappindicator3-1 libnspr4 libxss1 libgbm1 libfontconfig1
    
    - name: Install Playwright
      run: |
        pip install playwright
        playwright install chromium
        playwright install-deps chromium
    
    - name: Install Python dependencies
      run: |
        pip install -r backend/requirements.txt
    
    - name: Run daily scrape
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        SECRET_KEY: ${{ secrets.SECRET_KEY }}
        DEBUG: 'False'
        REDIS_URL: ${{ secrets.REDIS_URL }}
      run: |
        python manage.py migrate
        python manage.py scrape_daily


